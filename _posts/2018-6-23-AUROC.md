---
title: " Area Under Receiver Operating Characteristic curve (AUROC)"
date: 2018-06-23
tags: [machine learning, data science, AUROC, AUC ]
header:
  image: "/images/perceptron/percept.jpg"
excerpt: "Machine Learning, Perceptron, Data Science"
mathjax: "true"
---


**AUROC** (or implicitly shorten by **AUC**) is a metric to evaluate and compare the classification performance of machine learning models.
### Why not use accuracy?
 Accuracy is commonly used, but it is often not enough to reflect the efficiency of the models. Let review some basic definitions of binary-class prediction:
- **_True_ Positive (TP)**: when a sample is Positive, you predict it as **Positive**. (**_Right_**)
- **_False_ Negative (FN)**: when a sample is Positive, you predict it as **Negative**. (**_Wrong_**)
- **_False_ Positive (FP)**: when a sample is Negative, you predict it as **Positive**. (**_Wrong_**)
- **_True_ Negative (TN)**:  when a sample is Negative, you predict it as **Negative**. (**_Right_**)

In short, **TP, FN, FP, TN** is defined by **\[Right/Wrong\]\[Prediction Label\]**.

- Accuracy: $$acc = \frac{a}{b}$$



### How to compute it?



Here's some basic text.

And here's some *italics*

Here's some **bold** text.

What about a [link](https://github.com/dataoptimal)?

Here's a bulleted list:
* First item
+ Second item
- Third item

Here's a numbered list:
1. First
2. Second
3. Third

Python code block:
```python
    import numpy as np

    def test_function(x, y):
      z = np.sum(x,y)
      return z
```

R code block:
```r
library(tidyverse)
df <- read_csv("some_file.csv")
head(df)
```

Here's some inline code `x+y`.

Here's an image:
<img src="{{ site.url }}{{ site.baseurl }}/images/perceptron/linsep.jpg" alt="linearly separable data">

Here's another image using Kramdown:
![alt]({{ site.url }}{{ site.baseurl }}/images/perceptron/linsep.jpg)

Here's some math:

$$z=x+y$$

You can also put it inline $$z=x+y$$
