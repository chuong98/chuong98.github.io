---
title: " Area Under Receiver Operating Characteristic curve (AUROC)"
date: 2018-06-23
tags: [machine learning, data science, AUROC, AUC ]
header:
  image: "/images/perceptron/percept.jpg"
excerpt: "Machine Learning, Perceptron, Data Science"
mathjax: "true"
---


**AUROC** (or implicitly shorten by **AUC**) is a metric to evaluate and compare the classification performance of machine learning models.
### Why not use accuracy?
 Accuracy is commonly used, but somtimes it is not enough to reflect the efficiency of the models. Let review some basic definitions of binary-class prediction:
- **_True_ Positive (TP)**: when a sample is Positive, you predict it as **Positive**. (**_Right_**)
- **_False_ Negative (FN)**: when a sample is Positive, you predict it as **Negative**. (**_Wrong_**)
- **_False_ Positive (FP)**: when a sample is Negative, you predict it as **Positive**. (**_Wrong_**)
- **_True_ Negative (TN)**:  when a sample is Negative, you predict it as **Negative**. (**_Right_**)

In short, **TP, FN, FP, TN** is defined by **\[Right/Wrong\]\[Prediction Label\]**.

- **Accuracy Acc**: $$Acc = \frac{\text{Number of Correct Prediction}}{\text{Number of total samples}} = \frac{TP + TN}{TP+TN +FP +FN} $$
- **True Positive Rate ( or Sensitivity)(TPR)** : $$ TPR = \frac{\text{Number of Correct Predicted Positive}}{\text{Number of total Positive samples}} = \frac{TP}{TP+ FP} $$
- **False Positive Rate ( or Fall-out)(FPR)** : $$ TPR = \frac{\text{Number of InCorrect Predicted Positive}}{\text{Number of total Negative samples}} = \frac{FP}{TN+ FN} $$

Usually, the predictor, e.g. linear regression, outputs the probability of a sample belong to the Postive class, e.g. $$P(x \in \text{Positive}) = p$$. And we predict a sample as Positive if $$p \geq T$$, else Nagative. 

Hence, by varying the threshold $$T$$, we affecting the **TFR,TPR** and **ACC**.

### How to compute it?



Here's some basic text.

And here's some *italics*

Here's some **bold** text.

What about a [link](https://github.com/dataoptimal)?

Here's a bulleted list:
* First item
+ Second item
- Third item

Here's a numbered list:
1. First
2. Second
3. Third

Python code block:
```python
    import numpy as np

    def test_function(x, y):
      z = np.sum(x,y)
      return z
```

R code block:
```r
library(tidyverse)
df <- read_csv("some_file.csv")
head(df)
```

Here's some inline code `x+y`.

Here's an image:
<img src="{{ site.url }}{{ site.baseurl }}/images/perceptron/linsep.jpg" alt="linearly separable data">

Here's another image using Kramdown:
![alt]({{ site.url }}{{ site.baseurl }}/images/perceptron/linsep.jpg)

Here's some math:

$$z=x+y$$

You can also put it inline $$z=x+y$$
